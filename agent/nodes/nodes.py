# agent/nodes/nodes.py
import os
import json
import re
from typing import Any, Dict
from dotenv import load_dotenv
from langchain_upstage import ChatUpstage

from agent.prompts import (
    SUMMARY_DRAFT_PROMPT,
    QUIZ_FROM_SUMMARY_PROMPT,
    JUDGE_PROMPT,
    IMPROVE_DRAFT_PROMPT,
    CLASSIFY_PROMPT,
    THOUGHT_QUESTION_PROMPT,
    PERSONA_DEFINITIONS,
    PERSONA_APPLY_PROMPT,
)
from agent.utils import calculate_ebbinghaus_dates
from agent.rag import verify_summary_with_rag

load_dotenv()

# -----------------------------
# LLM
# -----------------------------
llm = ChatUpstage(
    model=os.getenv("KAFKA_MODEL", "solar-pro2"),
    temperature=0.2,
    api_key=os.environ["UPSTAGE_API_KEY"],
)


# -----------------------------
# Nodes
# -----------------------------
def classify_node(state):
    """0) ì½˜í…ì¸  ì„±ê²©ì„ ë¶„ì„í•˜ì—¬ 'ì§€ì‹í˜•' ë˜ëŠ” 'íë§í˜•'ìœ¼ë¡œ ë¶„ë¥˜ (CoT ì ìš©)"""
    article = state["input_text"]
    resp = llm.invoke(CLASSIFY_PROMPT + "\n\n[CONTENT]\n" + article[:2000])
    raw_output = (resp.content or "").strip()
    
    # "Category: [ì§€ì‹í˜•]" ë˜ëŠ” "Category: [íë§í˜•]"ì—ì„œ ì¶”ì¶œ
    if "ì§€ì‹í˜•" in raw_output:
        category = "ì§€ì‹í˜•"
    elif "íë§í˜•" in raw_output:
        category = "íë§í˜•"
    else:
        category = "ì§€ì‹í˜•"
        
    state["category"] = category
    return state


def synthesize_node(state):
    """1) ê¸°ì‚¬ ì›ë¬¸ìœ¼ë¡œ ìš”ì•½ ì´ˆì•ˆ(draft_summary)ë§Œ ìƒì„± (RAG ì‚¬ìš© X)"""
    article = state["input_text"]

    resp = llm.invoke(SUMMARY_DRAFT_PROMPT + "\n\n[ARTICLE]\n" + article)
    draft = (resp.content or "").strip()

    state["draft_summary"] = draft
    return state


def verify_node(state):
    """2) ìš”ì•½ ì´ˆì•ˆì„ RAGë¡œ ê²€ì¦(ê·¼ê±° ë¬¸ë§¥ êµ¬ì„±/ë¬¸ì¥ ê²€ì¦ ê²°ê³¼ ì €ì¥)"""
    article = state["input_text"]
    draft = state.get("draft_summary", "")

    # rag.pyì˜ ì›ë³¸ verify_summary_with_rag í˜¸ì¶œ (ì‹œê·¸ë‹ˆì²˜ì— ë§ì¶° ì§ì ‘ ì „ë‹¬)
    verified = verify_summary_with_rag(
        llm=llm,
        article_text=article,
        summary_draft=draft,
        per_sentence_k=3,
        relevance_threshold=0.12,
        max_context_chars=2800
    )

    state["query"] = verified.get("query", "")
    state["context"] = verified.get("context", "")
    state["citations"] = verified.get("citations", [])
    state["unsupported_sentences"] = verified.get("unsupported_sentences", [])

    verified_summary = verified.get("verified_summary", "")

    # ğŸ”§ ê³µë°± ì •ë¦¬ (ì´ìƒí•œ ì´ì¤‘ ê³µë°± ì œê±°)
    verified_summary = re.sub(r"\s+", " ", verified_summary).strip()

    state["summary"] = json.dumps(
        {
            "Summary": verified_summary,
            "UsedCitations": verified.get("used_citations", []),
            "Citations": verified.get("citations", []),
        },
        ensure_ascii=False,
    )


    # ì»¨í…ìŠ¤íŠ¸ê°€ ë¹„ì—ˆê±°ë‚˜ unsupportedê°€ ìˆìœ¼ë©´ ê°œì„  ë£¨í”„
    state["needs_improve"] = (not str(state["context"]).strip()) or (len(state["unsupported_sentences"]) > 0)

    return state


def judge_node(state):
    """3) ê²€ì¦ëœ CONTEXT vs SUMMARY faithfulness ì±„ì """
    context = state.get("context", "")
    summary_json = state.get("summary", "")

    try:
        s_obj = json.loads(summary_json)
        summary_text = s_obj.get("Summary", "")
    except Exception:
        summary_text = str(summary_json)

    resp = llm.invoke(
        JUDGE_PROMPT
        + "\n\n[CONTEXT]\n"
        + str(context)
        + "\n\n[SUMMARY]\n"
        + str(summary_text)
    )

    try:
        parsed = json.loads(resp.content)
    except Exception:
        parsed = {"score": 0, "needs_improve": True, "notes": "ì±„ì  JSON íŒŒì‹± ì‹¤íŒ¨"}

    score = int(parsed.get("score", 0))
    needs_improve = bool(parsed.get("needs_improve", score < 7))

    if state.get("unsupported_sentences"):
        needs_improve = True
        score = min(score, 6)

    state["judge_score"] = score
    state["needs_improve"] = needs_improve
    return state


def improve_node(state):
    """4) CONTEXT ê¸°ë°˜ìœ¼ë¡œ draft_summary(ì´ˆì•ˆ) ê°œì„ """
    max_improve = int(state.get("max_improve", 2))
    count = int(state.get("improve_count", 0))

    if count >= max_improve:
        state["needs_improve"] = False
        return state

    context = state.get("context", "")
    draft = state.get("draft_summary", "")

    resp = llm.invoke(
        IMPROVE_DRAFT_PROMPT
        + "\n\n[CONTEXT]\n"
        + str(context)
        + "\n\n[SUMMARY_DRAFT]\n"
        + str(draft)
    )

    improved_draft = (resp.content or "").strip()
    state["draft_summary"] = improved_draft
    state["improve_count"] = count + 1

    return state


def quiz_node(state):
    """(ì˜µì…˜) ìµœì¢… verified summary ê¸°ë°˜ í€´ì¦ˆ ë° ìƒê°ìœ ë„ì§ˆë¬¸ ìƒì„±"""
    category = state.get("category", "ì§€ì‹í˜•")

    # -----------------------------
    # 1ï¸âƒ£ Summary ì¶”ì¶œ
    # -----------------------------
    try:
        s_obj = json.loads(state.get("summary", ""))
        summary_text = s_obj.get("Summary", "")
    except Exception:
        summary_text = ""

    # ğŸ”¥ í€´ì¦ˆ ìƒì„±ìš©ì—ì„œëŠ” citation íƒœê·¸ ì œê±°
    summary_text = re.sub(r"\s*\[C\d+\]\s*", " ", summary_text).strip()
    
    # ì´ˆê¸°í™”: ì§€ì‹í˜•ì€ í€´ì¦ˆë§Œ, íë§í˜•ì€ ìƒê° ìœ ë„ ì§ˆë¬¸ë§Œ ë‚¨ê¸°ê¸° ìœ„í•¨
    state["thought_questions"] = []
    state["quiz"] = json.dumps({"questions": []}, ensure_ascii=False)
    # 1. ìƒê° ìœ ë„ ì§ˆë¬¸ ìƒì„± (ê³µí†µ)
    resp_thought = llm.invoke(
        THOUGHT_QUESTION_PROMPT 
        + f"\n\n[CATEGORY]: {category}"
        + "\n\n[SUMMARY]\n" + str(summary_text)
    )
    try:
        thought_questions = json.loads(resp_thought.content)
        state["thought_questions"] = thought_questions if isinstance(thought_questions, list) else []
    except Exception:
        state["thought_questions"] = []
    # 2. í€´ì¦ˆ ìƒì„± (ì§€ì‹í˜•ì¼ ë•Œë§Œ)
    if category == "ì§€ì‹í˜•":
        resp_quiz = llm.invoke(QUIZ_FROM_SUMMARY_PROMPT + "\n\n[SUMMARY]\n" + str(summary_text))
        try:
            quiz_obj = json.loads(resp_quiz.content)

            if isinstance(quiz_obj, dict) and "questions" in quiz_obj:
                state["quiz"] = json.dumps(quiz_obj, ensure_ascii=False)
            else:
                state["quiz"] = json.dumps({"questions": []}, ensure_ascii=False)
        except Exception:
            state["quiz"] = json.dumps({"questions": []}, ensure_ascii=False)
    else:

        # 2. íë§í˜•: ìƒê° ìœ ë„ ì§ˆë¬¸ë§Œ ìƒì„±
        resp_thought = llm.invoke(
            THOUGHT_QUESTION_PROMPT
            + f"\n\n[CATEGORY]: {category}"
            + "\n\n[SUMMARY]\n"
            + str(summary_text)
        )

        try:
            thought_questions = json.loads(resp_thought.content)

            if isinstance(thought_questions, list):
                state["thought_questions"] = thought_questions

        except Exception:
            pass
        state["quiz"] = json.dumps({"questions": []}, ensure_ascii=False)


    return state



# ============================================================
# í˜ë¥´ì†Œë‚˜ ì ìš© ë…¸ë“œ
# ============================================================

def persona_node(state):
    """
    í™•ì •ëœ ìš”ì•½ê³¼ í€´ì¦ˆ/ì§ˆë¬¸ì— í˜ë¥´ì†Œë‚˜ë¥¼ ì…í™ë‹ˆë‹¤.
    
    ë™ì‘:
    1. í˜„ì¬ í˜ë¥´ì†Œë‚˜ ì¹´ìš´í„°ë¥¼ í™•ì¸ (0-9 ìˆœí™˜)
    2. ì½˜í…ì¸  ìœ í˜•ì— ë”°ë¼ í€´ì¦ˆí˜•/ë¬¸ì¥í˜• í˜ë¥´ì†Œë‚˜ ì„ íƒ
    3. í˜ë¥´ì†Œë‚˜ ìŠ¤íƒ€ì¼ì„ ì ìš©í•œ ë©”ì‹œì§€ ìƒì„±
    
    ì´ìœ :
    - ë§¤ë²ˆ ê°™ì€ ë§íˆ¬ë¡œ ì•Œë¦¼ì´ ì˜¤ë©´ ì‚¬ìš©ìê°€ ì§€ë£¨í•´ì ¸ ì•Œë¦¼ì„ ì°¨ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - 10ê°€ì§€ í˜ë¥´ì†Œë‚˜ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì ìš©í•˜ì—¬ 'ì¹œêµ¬ê°€ ì•ˆë¶€ë¥¼ ë¬»ëŠ”' ëŠë‚Œì„ ì¤ë‹ˆë‹¤.
    """
    category = state.get("category", "ì§€ì‹í˜•")
    persona_count = int(state.get("persona_count", 0))
    
    # í˜ë¥´ì†Œë‚˜ ì„ íƒ (0-9 ìˆœí™˜)
    if category == "ì§€ì‹í˜•":
        persona_key = f"quiz_{persona_count % 5}"
    else:
        persona_key = f"thought_{persona_count % 5}"
    
    persona_def = PERSONA_DEFINITIONS.get(persona_key, PERSONA_DEFINITIONS["quiz_0"])
    
    # ì ìš©í•  ì½˜í…ì¸  ì¤€ë¹„
    try:
        s_obj = json.loads(state.get("summary", ""))
        summary_text = s_obj.get("Summary", "")
    except Exception:
        summary_text = state.get("summary", "")
    
    if category == "ì§€ì‹í˜•":
        quiz_text = state.get("quiz", "")
        content_to_style = f"[ìš”ì•½]\n{summary_text}\n\n[í€´ì¦ˆ]\n{quiz_text}"
    else:
        thought_text = "\n".join(state.get("thought_questions", []))
        content_to_style = f"[ìš”ì•½]\n{summary_text}\n\n[ìƒê° ìœ ë„ ì§ˆë¬¸]\n{thought_text}"
    
    # í˜ë¥´ì†Œë‚˜ ì ìš©
    prompt = PERSONA_APPLY_PROMPT.format(
        persona_definition=json.dumps(persona_def, ensure_ascii=False),
        content=content_to_style
    )
    
    resp = llm.invoke(prompt)
    styled_content = (resp.content or "").strip()
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    state["persona_style"] = persona_def["name"]
    state["styled_content"] = styled_content
    state["persona_count"] = persona_count + 1
    
    return state


# ============================================================
# ì—ë¹™í•˜ìš°ìŠ¤ ìŠ¤ì¼€ì¤„ë§ ë…¸ë“œ
# ============================================================

def schedule_node(state):
    """
    ì—ë¹™í•˜ìš°ìŠ¤ ë§ê° ê³¡ì„ ì— ë”°ë¼ ë³µìŠµ ì•Œë¦¼ ë‚ ì§œë¥¼ ê³„ì‚°í•˜ê³  íŒì—… ì•Œë¦¼ì„ ë°œì†¡í•©ë‹ˆë‹¤.
    
    ë™ì‘:
    1. ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ D+1, D+4, D+7, D+11 ê³„ì‚°
    2. ê³„ì‚°ëœ ë‚ ì§œë¥¼ ìƒíƒœì— ì €ì¥
    3. ë°ì´í„°ë² ì´ìŠ¤ì— ìŠ¤ì¼€ì¤„ ì˜êµ¬ ì €ì¥
    4. í¬ë¡œìŠ¤ í”Œë«í¼ íŒì—… ì•Œë¦¼ ë°œì†¡ (macOS + Windows)
    
    ì´ìœ : 
    - ì—ë¹™í•˜ìš°ìŠ¤ ë§ê° ê³¡ì„  ì´ë¡ :
      í•™ìŠµ ì§í›„ ë§ê°ì´ ê¸‰ê²©íˆ ì¼ì–´ë‚˜ì§€ë§Œ,
      ì ì ˆí•œ ì‹œì (1ì¼, 4ì¼, 7ì¼, 11ì¼)ì— ë³µìŠµí•˜ë©´
      ì •ë³´ê°€ ì¥ê¸° ê¸°ì–µìœ¼ë¡œ ì „í™˜ë©ë‹ˆë‹¤.
    - ë°œì†¡ ì‹œê°„: ì˜¤ì „ 8ì‹œ ì¶œê·¼ê¸¸ (ì¸ì§€ ë¶€í•˜ê°€ ì ì€ ì‹œê°„)
    - ì¼ì¼ ìµœëŒ€ 4íšŒ (ì•Œë¦¼ ìŠ¤íŠ¸ë ˆìŠ¤ ë°©ì§€ - ë“€ì˜¤ë§ê³  ë¬¸ì œì  ê°œì„ )
    - DB ì €ì¥: í”„ë¡œê·¸ë¨ ì¬ì‹œì‘ í›„ì—ë„ ìŠ¤ì¼€ì¤„ ìœ ì§€
    """
    schedule_dates = calculate_ebbinghaus_dates()
    state["schedule_dates"] = schedule_dates
    
    print(f"\nğŸ“… ì—ë¹™í•˜ìš°ìŠ¤ ì•Œë¦¼ ì˜ˆì•½ ì™„ë£Œ:")
    for i, date in enumerate(schedule_dates, 1):
        print(f"  {i}ì°¨ ì•Œë¦¼: {date} ì˜¤ì „ 8ì‹œ")
    
    # ğŸ†• ë°ì´í„°ë² ì´ìŠ¤ì— ìŠ¤ì¼€ì¤„ ì €ì¥
    try:
        from agent.database import get_db
        
        db = get_db()
        schedule_id = db.save_schedule(
            user_id="default_user",  # í–¥í›„ ì‹¤ì œ ì‚¬ìš©ì IDë¡œ ëŒ€ì²´
            schedule_dates=schedule_dates,
            styled_content=state.get("styled_content", ""),
            persona_style=state.get("persona_style", ""),
            persona_count=state.get("persona_count", 0),
            url=state.get("url", ""),
            summary=state.get("confirmed_summary", ""),
            category=state.get("category", "ì§€ì‹í˜•")
        )
        print(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ (Schedule ID: {schedule_id})")
    except Exception as e:
        print(f"\nâš ï¸  DB ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        print("   (ì•Œë¦¼ì€ ê³„ì† ì§„í–‰ë©ë‹ˆë‹¤)")
    
    # ğŸ†• í¬ë¡œìŠ¤ í”Œë«í¼ íŒì—… ì•Œë¦¼ ë°œì†¡
    try:
        from agent.notification.popup import schedule_popup_notifications
        
        schedule_popup_notifications(
            schedule_dates=schedule_dates,
            styled_content=state.get("styled_content", ""),
            persona_style=state.get("persona_style", ""),
            category=state.get("category", "ì§€ì‹í˜•")
        )
    except ImportError as e:
        print(f"\nâš ï¸  ì•Œë¦¼ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        print("   í•´ê²°: pip3 install plyer")
    except Exception as e:
        print(f"\nâš ï¸  ì•Œë¦¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return state
