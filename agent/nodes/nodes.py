# agent/nodes/nodes.py
import os
import json
from typing import Any, Dict

from langchain_upstage import ChatUpstage

from agent.prompts import (
    SUMMARY_DRAFT_PROMPT,
    QUIZ_FROM_SUMMARY_PROMPT,
    JUDGE_PROMPT,
    IMPROVE_DRAFT_PROMPT,
    CLASSIFY_PROMPT,
    THOUGHT_QUESTION_PROMPT,
    PERSONA_DEFINITIONS,
    PERSONA_APPLY_PROMPT,
)
from agent.utils import calculate_ebbinghaus_dates
from agent.rag import verify_summary_with_rag


# -----------------------------
# LLM
# -----------------------------
llm = ChatUpstage(
    model=os.getenv("KAFKA_MODEL", "solar-pro2"),
    temperature=0.2,
    api_key=os.environ["UPSTAGE_API_KEY"],
)


# -----------------------------
# Nodes
# -----------------------------
def classify_node(state):
    """0) ì½˜í…ì¸  ì„±ê²©ì„ ë¶„ì„í•˜ì—¬ 'ì§€ì‹í˜•' ë˜ëŠ” 'ì¼ë°˜í˜•'ìœ¼ë¡œ ë¶„ë¥˜ (CoT ì ìš©)"""
    article = state["input_text"]
    resp = llm.invoke(CLASSIFY_PROMPT + "\n\n[CONTENT]\n" + article[:2000])
    raw_output = (resp.content or "").strip()
    
    # "Category: [ì§€ì‹í˜•]" ë˜ëŠ” "Category: [ì¼ë°˜í˜•]"ì—ì„œ ì¶”ì¶œ
    if "ì§€ì‹í˜•" in raw_output:
        category = "ì§€ì‹í˜•"
    elif "ì¼ë°˜í˜•" in raw_output:
        category = "ì¼ë°˜í˜•"
    else:
        category = "ì§€ì‹í˜•"
        
    state["category"] = category
    return state


def synthesize_node(state):
    """1) ê¸°ì‚¬ ì›ë¬¸ìœ¼ë¡œ ìš”ì•½ ì´ˆì•ˆ(draft_summary)ë§Œ ìƒì„± (RAG ì‚¬ìš© X)"""
    article = state["input_text"]

    resp = llm.invoke(SUMMARY_DRAFT_PROMPT + "\n\n[ARTICLE]\n" + article)
    draft = (resp.content or "").strip()

    state["draft_summary"] = draft
    return state


def verify_node(state):
    """2) ìš”ì•½ ì´ˆì•ˆì„ RAGë¡œ ê²€ì¦(ê·¼ê±° ë¬¸ë§¥ êµ¬ì„±/ë¬¸ì¥ ê²€ì¦ ê²°ê³¼ ì €ì¥)"""
    article = state["input_text"]
    draft = state.get("draft_summary", "")

    # rag.pyì˜ ì›ë³¸ verify_summary_with_rag í˜¸ì¶œ (ì‹œê·¸ë‹ˆì²˜ì— ë§ì¶° ì§ì ‘ ì „ë‹¬)
    verified = verify_summary_with_rag(
        llm=llm,
        article_text=article,
        summary_draft=draft,
        per_sentence_k=3,
        relevance_threshold=0.12,
        max_context_chars=2800
    )

    state["query"] = verified.get("query", "")
    state["context"] = verified.get("context", "")
    state["citations"] = verified.get("citations", [])
    state["unsupported_sentences"] = verified.get("unsupported_sentences", [])

    verified_summary = verified.get("verified_summary", "")

    state["summary"] = json.dumps(
        {
            "Summary": verified_summary,
            "UsedCitations": verified.get("used_citations", []),
            "Citations": verified.get("citations", []),
        },
        ensure_ascii=False,
    )

    # ì»¨í…ìŠ¤íŠ¸ê°€ ë¹„ì—ˆê±°ë‚˜ unsupportedê°€ ìˆìœ¼ë©´ ê°œì„  ë£¨í”„
    state["needs_improve"] = (not str(state["context"]).strip()) or (len(state["unsupported_sentences"]) > 0)

    return state


def judge_node(state):
    """3) ê²€ì¦ëœ CONTEXT vs SUMMARY faithfulness ì±„ì """
    context = state.get("context", "")
    summary_json = state.get("summary", "")

    try:
        s_obj = json.loads(summary_json)
        summary_text = s_obj.get("Summary", "")
    except Exception:
        summary_text = str(summary_json)

    resp = llm.invoke(
        JUDGE_PROMPT
        + "\n\n[CONTEXT]\n"
        + str(context)
        + "\n\n[SUMMARY]\n"
        + str(summary_text)
    )

    try:
        parsed = json.loads(resp.content)
    except Exception:
        parsed = {"score": 0, "needs_improve": True, "notes": "ì±„ì  JSON íŒŒì‹± ì‹¤íŒ¨"}

    score = int(parsed.get("score", 0))
    needs_improve = bool(parsed.get("needs_improve", score < 7))

    if state.get("unsupported_sentences"):
        needs_improve = True
        score = min(score, 6)

    state["judge_score"] = score
    state["needs_improve"] = needs_improve
    return state


def improve_node(state):
    """4) CONTEXT ê¸°ë°˜ìœ¼ë¡œ draft_summary(ì´ˆì•ˆ) ê°œì„ """
    max_improve = int(state.get("max_improve", 2))
    count = int(state.get("improve_count", 0))

    if count >= max_improve:
        state["needs_improve"] = False
        return state

    context = state.get("context", "")
    draft = state.get("draft_summary", "")

    resp = llm.invoke(
        IMPROVE_DRAFT_PROMPT
        + "\n\n[CONTEXT]\n"
        + str(context)
        + "\n\n[SUMMARY_DRAFT]\n"
        + str(draft)
    )

    improved_draft = (resp.content or "").strip()
    state["draft_summary"] = improved_draft
    state["improve_count"] = count + 1

    return state


def quiz_node(state):
    """(ì˜µì…˜) ìµœì¢… verified summary ê¸°ë°˜ í€´ì¦ˆ ë° ìƒê°ìœ ë„ì§ˆë¬¸ ìƒì„±"""
    category = state.get("category", "ì§€ì‹í˜•")
    try:
        s_obj = json.loads(state.get("summary", ""))
        summary_text = s_obj.get("Summary", "")
    except Exception:
        summary_text = ""

    # 1. ìƒê° ìœ ë„ ì§ˆë¬¸ ìƒì„± (ê³µí†µ)
    resp_thought = llm.invoke(
        THOUGHT_QUESTION_PROMPT 
        + f"\n\n[CATEGORY]: {category}"
        + "\n\n[SUMMARY]\n" + str(summary_text)
    )
    try:
        thought_questions = json.loads(resp_thought.content)
        state["thought_questions"] = thought_questions if isinstance(thought_questions, list) else []
    except Exception:
        state["thought_questions"] = []

    # 2. í€´ì¦ˆ ìƒì„± (ì§€ì‹í˜•ì¼ ë•Œë§Œ)
    if category == "ì§€ì‹í˜•":
        resp_quiz = llm.invoke(QUIZ_FROM_SUMMARY_PROMPT + "\n\n[SUMMARY]\n" + str(summary_text))
        try:
            quiz_obj = json.loads(resp_quiz.content)
            if isinstance(quiz_obj, dict) and ("questions" in quiz_obj):
                state["quiz"] = json.dumps(quiz_obj, ensure_ascii=False)
            else:
                state["quiz"] = json.dumps({"questions": []}, ensure_ascii=False)
        except Exception:
            state["quiz"] = json.dumps({"questions": []}, ensure_ascii=False)
    else:
        state["quiz"] = json.dumps({"questions": []}, ensure_ascii=False)

    return state


# ============================================================
# ğŸ†• í˜ë¥´ì†Œë‚˜ ì ìš© ë…¸ë“œ
# ============================================================

def persona_node(state):
    """
    í™•ì •ëœ ìš”ì•½ê³¼ í€´ì¦ˆ/ì§ˆë¬¸ì— í˜ë¥´ì†Œë‚˜ë¥¼ ì…í™ë‹ˆë‹¤.
    
    ë™ì‘:
    1. í˜„ì¬ í˜ë¥´ì†Œë‚˜ ì¹´ìš´í„°ë¥¼ í™•ì¸ (0-9 ìˆœí™˜)
    2. ì½˜í…ì¸  ìœ í˜•ì— ë”°ë¼ í€´ì¦ˆí˜•/ë¬¸ì¥í˜• í˜ë¥´ì†Œë‚˜ ì„ íƒ
    3. í˜ë¥´ì†Œë‚˜ ìŠ¤íƒ€ì¼ì„ ì ìš©í•œ ë©”ì‹œì§€ ìƒì„±
    
    ì´ìœ :
    - ë§¤ë²ˆ ê°™ì€ ë§íˆ¬ë¡œ ì•Œë¦¼ì´ ì˜¤ë©´ ì‚¬ìš©ìê°€ ì§€ë£¨í•´ì ¸ ì•Œë¦¼ì„ ì°¨ë‹¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - 10ê°€ì§€ í˜ë¥´ì†Œë‚˜ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì ìš©í•˜ì—¬ 'ì¹œêµ¬ê°€ ì•ˆë¶€ë¥¼ ë¬»ëŠ”' ëŠë‚Œì„ ì¤ë‹ˆë‹¤.
    """
    category = state.get("category", "ì§€ì‹í˜•")
    persona_count = int(state.get("persona_count", 0))
    
    # í˜ë¥´ì†Œë‚˜ ì„ íƒ (0-9 ìˆœí™˜)
    if category == "ì§€ì‹í˜•":
        persona_key = f"quiz_{persona_count % 5}"
    else:
        persona_key = f"thought_{persona_count % 5}"
    
    persona_def = PERSONA_DEFINITIONS.get(persona_key, PERSONA_DEFINITIONS["quiz_0"])
    
    # ì ìš©í•  ì½˜í…ì¸  ì¤€ë¹„
    try:
        s_obj = json.loads(state.get("summary", ""))
        summary_text = s_obj.get("Summary", "")
    except Exception:
        summary_text = state.get("summary", "")
    
    if category == "ì§€ì‹í˜•":
        quiz_text = state.get("quiz", "")
        content_to_style = f"[ìš”ì•½]\n{summary_text}\n\n[í€´ì¦ˆ]\n{quiz_text}"
    else:
        thought_text = "\n".join(state.get("thought_questions", []))
        content_to_style = f"[ìš”ì•½]\n{summary_text}\n\n[ìƒê° ìœ ë„ ì§ˆë¬¸]\n{thought_text}"
    
    # í˜ë¥´ì†Œë‚˜ ì ìš©
    prompt = PERSONA_APPLY_PROMPT.format(
        persona_definition=json.dumps(persona_def, ensure_ascii=False),
        content=content_to_style
    )
    
    resp = llm.invoke(prompt)
    styled_content = (resp.content or "").strip()
    
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    state["persona_style"] = persona_def["name"]
    state["styled_content"] = styled_content
    state["persona_count"] = persona_count + 1
    
    return state


# ============================================================
# ğŸ†• ì—ë¹™í•˜ìš°ìŠ¤ ìŠ¤ì¼€ì¤„ë§ ë…¸ë“œ
# ============================================================

def schedule_node(state):
    """
    ì—ë¹™í•˜ìš°ìŠ¤ ë§ê° ê³¡ì„ ì— ë”°ë¼ ë³µìŠµ ì•Œë¦¼ ë‚ ì§œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    ë™ì‘:
    1. ì˜¤ëŠ˜ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ D+1, D+4, D+7, D+11 ê³„ì‚°
    2. ê³„ì‚°ëœ ë‚ ì§œë¥¼ ìƒíƒœì— ì €ì¥
    
    ì´ìœ :
    - ì—ë¹™í•˜ìš°ìŠ¤ ë§ê° ê³¡ì„  ì´ë¡ :
      í•™ìŠµ ì§í›„ ë§ê°ì´ ê¸‰ê²©íˆ ì¼ì–´ë‚˜ì§€ë§Œ,
      ì ì ˆí•œ ì‹œì (1ì¼, 4ì¼, 7ì¼, 11ì¼)ì— ë³µìŠµí•˜ë©´
      ì •ë³´ê°€ ì¥ê¸° ê¸°ì–µìœ¼ë¡œ ì „í™˜ë©ë‹ˆë‹¤.
    - ë°œì†¡ ì‹œê°„ì€ 'ì˜¤ì „ 8ì‹œ ì¶œê·¼ê¸¸'ì´ ê¶Œì¥ë˜ì§€ë§Œ,
      ì‹¤ì œ ë°œì†¡ ì‹œìŠ¤í…œì€ ë³„ë„ ìŠ¤ì¼€ì¤„ëŸ¬(Celery ë“±)ì—ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    schedule_dates = calculate_ebbinghaus_dates()
    state["schedule_dates"] = schedule_dates
    
    print(f"\nğŸ“… ì—ë¹™í•˜ìš°ìŠ¤ ì•Œë¦¼ ì˜ˆì•½ ì™„ë£Œ:")
    for i, date in enumerate(schedule_dates, 1):
        print(f"  {i}ì°¨ ì•Œë¦¼: {date} ì˜¤ì „ 8ì‹œ")
    
    return state
