import os
import json
import re
from typing import Any
from dotenv import load_dotenv
from langchain_upstage import ChatUpstage

from agent.prompts import (
    SUMMARY_DRAFT_PROMPT,
    QUIZ_FROM_SUMMARY_PROMPT,
    JUDGE_PROMPT,
    IMPROVE_DRAFT_PROMPT,
    CLASSIFY_PROMPT,
    THOUGHT_QUESTION_PROMPT,
    PERSONA_DEFINITIONS,
    PERSONA_APPLY_PROMPT,
)
from agent.utils import calculate_ebbinghaus_dates
from agent.rag import verify_summary_with_rag
from agent.eval_pairwise import eval_rag_vs_llm  # âœ… ì—¬ê¸° ìˆëŠ” í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ì— ë§ì¶° í˜¸ì¶œí•´ì•¼ í•¨

load_dotenv()

# -----------------------------
# LLM
# -----------------------------
llm = ChatUpstage(
    model=os.getenv("KAFKA_MODEL", "solar-pro2"),
    temperature=0.2,
    api_key=os.environ["UPSTAGE_API_KEY"],
)


# -----------------------------
# Helpers
# -----------------------------
_CIT_RE = re.compile(r"\[C\d+\]")

def _extract_text(x: Any) -> str:
    """summaryê°€ str/json(dict)/None ë“±ìœ¼ë¡œ ë“¤ì–´ì™€ë„ ë¹„êµìš© í…ìŠ¤íŠ¸ë¥¼ ì•ˆì •ì ìœ¼ë¡œ ë½‘ìŠµë‹ˆë‹¤."""
    if x is None:
        return ""
    if isinstance(x, str):
        s = x.strip()
        try:
            obj = json.loads(s)
            if isinstance(obj, dict):
                for k in ["Summary", "summary", "ìš”ì•½", "text", "content"]:
                    if k in obj and isinstance(obj[k], str):
                        return obj[k].strip()
        except Exception:
            pass
        return s
    if isinstance(x, dict):
        for k in ["Summary", "summary", "ìš”ì•½", "text", "content"]:
            if k in x and isinstance(x[k], str):
                return x[k].strip()
        return json.dumps(x, ensure_ascii=False)
    return str(x).strip()


# -----------------------------
# Nodes
# -----------------------------
def classify_node(state):
    """0) ì½˜í…ì¸  ì„±ê²©ì„ ë¶„ì„í•˜ì—¬ 'ì§€ì‹í˜•' ë˜ëŠ” 'íë§í˜•'ìœ¼ë¡œ ë¶„ë¥˜"""
    article = state["input_text"]
    resp = llm.invoke(CLASSIFY_PROMPT + "\n\n[CONTENT]\n" + article[:2000])
    raw_output = (resp.content or "").strip()

    if "ì§€ì‹í˜•" in raw_output:
        category = "ì§€ì‹í˜•"
    elif "íë§í˜•" in raw_output:
        category = "íë§í˜•"
    else:
        category = "ì§€ì‹í˜•"

    state["category"] = category
    return state


def synthesize_node(state):
    """1) ê¸°ì‚¬ ì›ë¬¸ìœ¼ë¡œ ìš”ì•½ ì´ˆì•ˆ(draft_summary)ë§Œ ìƒì„± (RAG ì‚¬ìš© X)"""
    article = state["input_text"]
    resp = llm.invoke(SUMMARY_DRAFT_PROMPT + "\n\n[ARTICLE]\n" + article)
    draft = (resp.content or "").strip()

    state["draft_summary"] = draft
    return state


def verify_node(state):
    """2) ìš”ì•½ ì´ˆì•ˆì„ RAGë¡œ ê²€ì¦(ê·¼ê±° ë¬¸ë§¥ êµ¬ì„±/ë¬¸ì¥ ê²€ì¦ ê²°ê³¼ ì €ì¥)"""
    article = state["input_text"]
    draft = state.get("draft_summary", "")

    verified = verify_summary_with_rag(
        llm=llm,
        article_text=article,
        summary_draft=draft,
        per_sentence_k=3,
        relevance_threshold=0.12,
        max_context_chars=2800
    )

    state["query"] = verified.get("query", "")
    state["context"] = verified.get("context", "")
    state["citations"] = verified.get("citations", [])
    state["unsupported_sentences"] = verified.get("unsupported_sentences", [])

    verified_summary = verified.get("verified_summary", "")
    verified_summary = re.sub(r"\s+", " ", verified_summary).strip()

    # RAG ê²€ì¦ ìš”ì•½ì€ ì¼ë‹¨ JSON í˜•íƒœë¡œ ì €ì¥(ë””ë²„ê·¸/DBìš©)
    state["summary"] = json.dumps(
        {
            "Summary": verified_summary,
            "UsedCitations": verified.get("used_citations", []),
            "Citations": verified.get("citations", []),
        },
        ensure_ascii=False,
    )

    # ì»¨í…ìŠ¤íŠ¸ê°€ ë¹„ì—ˆê±°ë‚˜ unsupportedê°€ ìˆìœ¼ë©´ ê°œì„  ë£¨í”„
    state["needs_improve"] = (not str(state["context"]).strip()) or (len(state["unsupported_sentences"]) > 0)
    return state


def ab_select_node(state: dict):
    """
    - A: state['draft_summary'] (LLM-only)
    - B: state['summary'] (RAG ê²€ì¦ ìš”ì•½: JSON stringì¼ ìˆ˜ ìˆìŒ)
    ëª©í‘œ: A/B ë¹„êµ í›„ ë” ë‚˜ì€ ìª½ì„ ìµœì¢… summaryë¡œ ì±„íƒ.
    """
    do_ab = bool(state.get("do_ab_eval", True))
    a_raw = state.get("draft_summary")
    b_raw = state.get("summary")

    a = _extract_text(a_raw)
    b = _extract_text(b_raw)

    # í‰ê°€ í¸í–¥ ì¤„ì´ê¸°: RAG ìš”ì•½ì˜ [C1] ê°™ì€ íƒœê·¸ ì œê±°í•˜ê³  ë¹„êµ
    a_for_eval = a
    b_for_eval = _CIT_RE.sub("", b)

    report = None
    winner = None

    if do_ab and a_for_eval and b_for_eval:
        try:
            # âœ… eval_pairwise.pyì˜ ì‹¤ì œ ì‹œê·¸ë‹ˆì²˜ì— ë§ì¶¤
            report = eval_rag_vs_llm(
                llm=llm,
                article_text=state.get("input_text", ""),
                draft_summary=a_for_eval,
                rag_summary=b_for_eval,
            )
            winner = (report.get("overall") or {}).get("winner")
        except Exception as e:
            report = {"error": f"{type(e).__name__}: {e}"}
            winner = None

    # ìµœì¢… ì„ íƒ ë¡œì§
    if winner == "A":
        final = a
        final_source = "A"
    elif winner == "B":
        final = b
        final_source = "B"
    else:
        # ë¹„êµ ë¶ˆê°€ / TIE -> RAG ìš°ì„ 
        final = b or a or ""
        final_source = "B" if b else ("A" if a else "NONE")

    # downstreamì€ state["summary"]ë§Œ ë³´ë©´ ë¨
    return {
        "pairwise_eval": report,
        "winner": final_source,
        "rag_summary": b_raw,   # ë””ë²„ê¹…ìš©(ì›ë³¸ ë³´ì¡´)
        "summary": final,       # âœ… ìµœì¢… ìš”ì•½(í…ìŠ¤íŠ¸)
    }


def judge_node(state):
    """3) CONTEXT vs SUMMARY faithfulness ì±„ì """
    context = state.get("context", "")
    summary_val = state.get("summary", "")

    # summaryê°€ JSONì¼ ìˆ˜ë„/í…ìŠ¤íŠ¸ì¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
    summary_text = _extract_text(summary_val)

    resp = llm.invoke(
        JUDGE_PROMPT
        + "\n\n[CONTEXT]\n"
        + str(context)
        + "\n\n[SUMMARY]\n"
        + str(summary_text)
    )

    try:
        parsed = json.loads(resp.content)
    except Exception:
        parsed = {"score": 0, "needs_improve": True, "notes": "ì±„ì  JSON íŒŒì‹± ì‹¤íŒ¨"}

    score = int(parsed.get("score", 0))
    needs_improve = bool(parsed.get("needs_improve", score < 7))

    if state.get("unsupported_sentences"):
        needs_improve = True
        score = min(score, 6)

    state["judge_score"] = score
    state["needs_improve"] = needs_improve
    return state


def improve_node(state):
    """4) CONTEXT ê¸°ë°˜ìœ¼ë¡œ draft_summary(ì´ˆì•ˆ) ê°œì„ """
    max_improve = int(state.get("max_improve", 2))
    count = int(state.get("improve_count", 0))

    if count >= max_improve:
        state["needs_improve"] = False
        return state

    context = state.get("context", "")
    draft = state.get("draft_summary", "")

    resp = llm.invoke(
        IMPROVE_DRAFT_PROMPT
        + "\n\n[CONTEXT]\n"
        + str(context)
        + "\n\n[SUMMARY_DRAFT]\n"
        + str(draft)
    )

    improved_draft = (resp.content or "").strip()
    state["draft_summary"] = improved_draft
    state["improve_count"] = count + 1
    return state


def quiz_node(state):
    """ìµœì¢… summary ê¸°ë°˜ í€´ì¦ˆ/ìƒê°ìœ ë„ì§ˆë¬¸ ìƒì„±"""
    category = state.get("category", "ì§€ì‹í˜•")

    summary_text = _extract_text(state.get("summary", ""))
    summary_text = re.sub(r"\s*\[C\d+\]\s*", " ", summary_text).strip()

    state["thought_questions"] = []
    state["quiz"] = json.dumps({"questions": []}, ensure_ascii=False)

    if category == "ì§€ì‹í˜•":
        resp_quiz = llm.invoke(QUIZ_FROM_SUMMARY_PROMPT + "\n\n[SUMMARY]\n" + str(summary_text))
        try:
            quiz_obj = json.loads(resp_quiz.content)
            if isinstance(quiz_obj, dict) and "questions" in quiz_obj:
                state["quiz"] = json.dumps(quiz_obj, ensure_ascii=False)
        except Exception:
            pass
    else:
        resp_thought = llm.invoke(
            THOUGHT_QUESTION_PROMPT
            + f"\n\n[CATEGORY]: {category}"
            + "\n\n[SUMMARY]\n" + str(summary_text)
        )
        try:
            thought_questions = json.loads(resp_thought.content)
            state["thought_questions"] = thought_questions if isinstance(thought_questions, list) else []
        except Exception:
            pass

    return state


def persona_node(state):
    """í˜ë¥´ì†Œë‚˜ ì ìš©"""
    category = state.get("category", "ì§€ì‹í˜•")
    persona_count = int(state.get("persona_count", 0))

    if category == "ì§€ì‹í˜•":
        persona_key = f"quiz_{persona_count % 5}"
    else:
        persona_key = f"thought_{persona_count % 5}"

    persona_def = PERSONA_DEFINITIONS.get(persona_key, PERSONA_DEFINITIONS["quiz_0"])

    summary_text = _extract_text(state.get("summary", ""))

    if category == "ì§€ì‹í˜•":
        quiz_text = state.get("quiz", "")
        content_to_style = f"[ìš”ì•½]\n{summary_text}\n\n[í€´ì¦ˆ]\n{quiz_text}"
    else:
        thought_text = "\n".join(state.get("thought_questions", []))
        content_to_style = f"[ìš”ì•½]\n{summary_text}\n\n[ìƒê° ìœ ë„ ì§ˆë¬¸]\n{thought_text}"

    prompt = PERSONA_APPLY_PROMPT.format(
        persona_definition=json.dumps(persona_def, ensure_ascii=False),
        content=content_to_style
    )

    resp = llm.invoke(prompt)
    styled_content = (resp.content or "").strip()

    state["persona_style"] = persona_def["name"]
    state["styled_content"] = styled_content
    state["persona_count"] = persona_count + 1
    return state


def schedule_node(state):
    """ì—ë¹™í•˜ìš°ìŠ¤ ìŠ¤ì¼€ì¤„ë§ + DB ì €ì¥ + íŒì—…"""
    schedule_dates = calculate_ebbinghaus_dates()
    state["schedule_dates"] = schedule_dates

    print(f"\nğŸ“… ì—ë¹™í•˜ìš°ìŠ¤ ì•Œë¦¼ ì˜ˆì•½ ì™„ë£Œ:")
    for i, date in enumerate(schedule_dates, 1):
        print(f"  {i}ì°¨ ì•Œë¦¼: {date} ì˜¤ì „ 8ì‹œ")

    # DB ì €ì¥
    try:
        from agent.database import get_db
        db = get_db()

        url = state.get("url", "") or state.get("input_text", "")

        summary_text = _extract_text(state.get("summary", ""))

        schedule_id = db.save_schedule(
            user_id="default_user",
            schedule_dates=schedule_dates,
            styled_content=state.get("styled_content", ""),
            persona_style=state.get("persona_style", ""),
            persona_count=state.get("persona_count", 0),
            url=url,
            summary=summary_text,
            category=state.get("category", "ì§€ì‹í˜•")
        )
        print(f"ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ (Schedule ID: {schedule_id})")
        print(f"   - URL: {url[:50] if url else '(í…ìŠ¤íŠ¸ ì…ë ¥)'}...")
        print(f"   - ìš”ì•½: {summary_text[:50] if summary_text else '(ì—†ìŒ)'}...")
    except Exception as e:
        print(f"\nâš ï¸  DB ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        print("   (ì•Œë¦¼ì€ ê³„ì† ì§„í–‰ë©ë‹ˆë‹¤)")

    # íŒì—… ì•Œë¦¼
    try:
        from agent.notification.popup import schedule_popup_notifications

        schedule_popup_notifications(
            schedule_dates=schedule_dates,
            styled_content=state.get("styled_content", ""),
            persona_style=state.get("persona_style", ""),
            category=state.get("category", "ì§€ì‹í˜•")
        )
    except ImportError as e:
        print(f"\nâš ï¸  ì•Œë¦¼ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        print("   í•´ê²°: pip3 install plyer")
    except Exception as e:
        print(f"\nâš ï¸  ì•Œë¦¼ ë°œì†¡ ì¤‘ ì˜¤ë¥˜: {e}")

    return state
