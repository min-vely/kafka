import os
import json
import re
from typing import Any, Dict, List, Tuple, Optional

from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever

# âœ… LangChain ë²„ì „ ì°¨ì´(íŒ¨í‚¤ì§€/ê²½ë¡œ) í˜¸í™˜ ì²˜ë¦¬
try:
    from langchain.text_splitter import CharacterTextSplitter  # êµ¬ë²„ì „
except Exception:
    from langchain_text_splitters import CharacterTextSplitter  # ìµœì‹  ë¶„ë¦¬ íŒ¨í‚¤ì§€

from agent.prompts import QUERY_REWRITE_PROMPT, RERANK_PROMPT


# -----------------------------
# 1) Vectorstore / Query Rewrite
# -----------------------------

try:
    from langchain_text_splitters import RecursiveCharacterTextSplitter
except Exception:
    from langchain.text_splitter import RecursiveCharacterTextSplitter


def build_vectorstore(text: str) -> FAISS:
    """ê¸°ì‚¬ ì›ë¬¸ì„ ì²­í¬ë¡œ ìª¼ê°œ ì„ë² ë”©í•œ ë’¤, FAISS ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=250,
        chunk_overlap=60,
        separators=["\n\n", "\n", ". ", "? ", "! ", " "],
    )
    chunks = splitter.split_text(text or "")

    embeddings = UpstageEmbeddings(
        model="solar-embedding-1-large",
        api_key=os.environ["UPSTAGE_API_KEY"],
    )
    return FAISS.from_texts(chunks, embeddings)


def rewrite_query(llm: ChatUpstage, article_text: str) -> str:
    """ê¸°ì‚¬ ì¼ë¶€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰ ìµœì í™” ì¿¼ë¦¬ë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ ì¬ì‘ì„±í•©ë‹ˆë‹¤."""
    snippet = (article_text or "")[:1800]
    prompt = QUERY_REWRITE_PROMPT.strip() + "\n\n" + snippet

    resp = llm.invoke(prompt)

    content = ""
    try:
        content = (resp.content or "").strip()
    except Exception:
        content = str(resp).strip()

    # ë”°ì˜´í‘œ/ì¡ìŒ ì œê±°
    content = content.strip().strip('"').strip("'").strip()

    # ë¹ˆ ê°’ fallback
    if not content:
        content = "ê¸°ì‚¬ í•µì‹¬(ìˆ˜ì¹˜/ë¹„êµ/ê¸°ëŠ¥/ì¡°ê±´/ë°œì–¸)ì„ ìš”ì•½í•˜ê¸° ìœ„í•œ ê·¼ê±° ë¬¸ì¥ ê²€ìƒ‰ ì¿¼ë¦¬"

    # âœ… ì—¬ê¸°ì„œ ë°˜ë“œì‹œ ì •ë¦¬
    content = _clean_llm_query_output(content)

    return content


def _to_relevance(score: float) -> float:
    """FAISS scoreë¥¼ 0~1 relevanceë¡œ ë³€í™˜."""
    try:
        return 1.0 / (1.0 + float(score))
    except Exception:
        return 0.0


# âœ… rewrite_query ì¶œë ¥ì—ì„œ ë©”íƒ€ í…ìŠ¤íŠ¸/ë”°ì˜´í‘œ/ë§ˆí¬ë‹¤ìš´ ì œê±°
def _clean_llm_query_output(s: str, max_len: int = 160) -> str:
    s = (s or "").strip()

    # 1) ë¼ë²¨ ì œê±°
    s = re.sub(r"^\*+\s*ì¿¼ë¦¬\s*\*+\s*:\s*", "", s, flags=re.IGNORECASE)
    s = re.sub(r"^\s*query\s*:\s*", "", s, flags=re.IGNORECASE)

    # 2) í° ë¸”ë¡ì´ ì‹œì‘ë˜ëŠ” ì§€ì ì—ì„œ 'ì˜ë¼ë‚´ê¸°'
    cut_markers = [
        "\n",
        "citations:",
        "**ìµœì¢…",
        "ìµœì¢… ì¶œë ¥",
        "ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­",
        "(â€»",
    ]
    for m in cut_markers:
        if m in s:
            s = s.split(m, 1)[0].strip()

    # 3) ë”°ì˜´í‘œë¡œ ì‹œì‘í•˜ëŠ” 'ë‘ ë²ˆì§¸ ë©ì–´ë¦¬'ê°€ ë¶™ëŠ” ê²½ìš° ì˜ë¼ë‚´ê¸°
    if ' "' in s:
        s = s.split(' "', 1)[0].strip()
    if '"' in s and s.count('"') >= 1:
        s = s.split('"', 1)[0].strip()

    # 4) ë©”íƒ€ ë¬¸êµ¬ ì œê±°
    s = re.sub(r"\*\*ìµœì¢…\s*ë‹µë³€\*\*|ìµœì¢…\s*ë‹µë³€|ì‹¤ì œ\s*ë‹µë³€", "", s).strip()

    # 5) ê³µë°±/ë”°ì˜´í‘œ ì •ë¦¬
    s = s.strip().strip('"').strip("'")
    s = re.sub(r"\s+", " ", s).strip()

    # 6) ê¸¸ì´ ì œí•œ
    if len(s) > max_len:
        s = s[:max_len].rstrip(" ,.;")

    return s


# -----------------------------
# 2) Retriever (optional rerank)
# -----------------------------
def retrieve_candidates(vs: FAISS, query: str, k: int = 8) -> List[Dict[str, Any]]:
    pairs = vs.similarity_search_with_score(query, k=k)
    cands: List[Dict[str, Any]] = []
    for idx, (doc, score) in enumerate(pairs, start=1):
        cid = f"C{idx}"
        cands.append(
            {
                "id": cid,
                "text": doc.page_content,
                "score": float(score),
                "relevance": _to_relevance(score),
            }
        )
    return cands


def rerank_with_llm(
    llm: ChatUpstage, query: str, candidates: List[Dict[str, Any]], take: int = 4
) -> List[Dict[str, Any]]:
    """
    LLMìœ¼ë¡œ í›„ë³´ë¥¼ ì¬ì •ë ¬í•©ë‹ˆë‹¤.
    RERANK_PROMPTëŠ” ["C3","C1",...] ê°™ì€ id ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ë„ë¡ ì„¤ê³„ë˜ì–´ì•¼ í•¨.
    ì‹¤íŒ¨ ì‹œ relevance ìˆœìœ¼ë¡œ fallback.
    """
    payload = {
        "query": query,
        "candidates": [
            {"id": c["id"], "text": (c["text"][:400] if c.get("text") else "")}
            for c in candidates
        ],
    }

    resp = llm.invoke(RERANK_PROMPT + "\n\n" + json.dumps(payload, ensure_ascii=False))

    picked_ids: List[str] = []
    try:
        picked = json.loads(resp.content)
        if isinstance(picked, list):
            picked_ids = [x for x in picked if isinstance(x, str)]
    except Exception:
        picked_ids = []

    if not picked_ids:
        picked_ids = [
            c["id"]
            for c in sorted(candidates, key=lambda x: x["relevance"], reverse=True)[:take]
        ]

    id2 = {c["id"]: c for c in candidates}
    ranked = [id2[i] for i in picked_ids if i in id2]
    return ranked[:take]


def pack_context(
    ranked: List[Dict[str, Any]], max_chars: int = 2800
) -> Tuple[str, List[Dict[str, Any]]]:
    """
    ì„ ì •ëœ ê·¼ê±°ë¥¼ [C#] ë§ˆì»¤ì™€ í•¨ê»˜ í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ì¢‹ì€ ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤.
    ë°˜í™˜: (context_str, citations=[{"id": "C1", "text": "..."}...])
    """
    seen = set()
    packed: List[Dict[str, Any]] = []
    total = 0

    for c in ranked:
        t = (c.get("text") or "").strip()
        if not t or t in seen:
            continue
        seen.add(t)

        piece = f"[{c['id']}] {t}"
        if total + len(piece) > max_chars:
            break

        packed.append({"id": c["id"], "text": t})
        total += len(piece)

    context = "\n\n".join([f"[{p['id']}] {p['text']}" for p in packed])
    return context, packed


class KafkaMiniRetriever(BaseRetriever):
    """í˜„ì¬ í”„ë¡œì íŠ¸ RAG ê²€ìƒ‰ ë¡œì§ì„ LangChain Retriever í˜•íƒœë¡œ ë˜í•‘."""
    model_config = {"arbitrary_types_allowed": True}

    vectorstore: FAISS
    llm: ChatUpstage
    top_k: int = 8
    relevance_threshold: float = 0.20
    rerank_top: int = 4

    def _get_relevant_documents(self, query: str) -> List[Document]:
        candidates = retrieve_candidates(self.vectorstore, query=query, k=self.top_k)
        filtered = [c for c in candidates if c["relevance"] >= self.relevance_threshold]
        if not filtered:
            return []

        ranked = rerank_with_llm(
            self.llm, query=query, candidates=filtered, take=self.rerank_top
        )

        docs: List[Document] = []
        for c in ranked:
            docs.append(
                Document(
                    page_content=c["text"],
                    metadata={
                        "cid": c["id"],
                        "score": c["score"],
                        "relevance": c["relevance"],
                    },
                )
            )
        return docs


# -----------------------------
# 3) Public: retrieve_context()
# -----------------------------
def retrieve_context(
    llm: ChatUpstage,
    article_text: str,
    top_k: int = 8,
    rerank_top: int = 4,
    relevance_threshold: float = 0.20,
    max_context_chars: int = 2800,
) -> Tuple[str, str, List[Dict[str, Any]]]:
    """
    ê¸°ì‚¬ â†’ (FAISS) â†’ ì¿¼ë¦¬ ì¬ì‘ì„± â†’ Retriever ê²€ìƒ‰ â†’ pack â†’ ë°˜í™˜
    ë°˜í™˜: (query, context, citations)
    """
    vs = build_vectorstore(article_text)
    query = rewrite_query(llm, article_text)

    retriever = KafkaMiniRetriever(
        vectorstore=vs,
        llm=llm,
        top_k=top_k,
        relevance_threshold=relevance_threshold,
        rerank_top=rerank_top,
    )

    try:
        docs = retriever.invoke(query)
    except Exception:
        docs = retriever.get_relevant_documents(query)

    ranked = [
        {
            "id": (d.metadata.get("cid") or "C?"),
            "text": d.page_content,
            "score": float(d.metadata.get("score", 0.0)),
            "relevance": float(d.metadata.get("relevance", 0.0)),
        }
        for d in (docs or [])
    ]

    if not ranked:
        return query, "", []

    context, citations = pack_context(ranked, max_chars=max_context_chars)
    return query, context, citations


# -----------------------------
# (NEW) 3.5) A/B helpers
# -----------------------------
def _make_rag_summary(llm: ChatUpstage, context: str) -> str:
    """
    CONTEXTë§Œì„ ê·¼ê±°ë¡œ ê°„ê²° ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    (ê·œì¹™: ì»¨í…ìŠ¤íŠ¸ ì™¸ ì •ë³´ ì¶”ê°€ ê¸ˆì§€)
    """
    context = (context or "").strip()
    if not context:
        return ""

    prompt = (
        "ë‹¹ì‹ ì€ ì£¼ì–´ì§„ CONTEXTë§Œì„ ê·¼ê±°ë¡œ ìš”ì•½í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n"
        "ê·œì¹™:\n"
        "- CONTEXTì— ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.\n"
        "- 3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ì„¸ìš”.\n"
        "- ê³¼ì¥/ì¶”ì¸¡/ì¼ë°˜ë¡  ê¸ˆì§€.\n\n"
        f"CONTEXT:\n{context}\n\n"
        "ì¶œë ¥: 3ë¬¸ì¥ ìš”ì•½"
    )

    resp = llm.invoke(prompt)
    try:
        return (resp.content or "").strip()
    except Exception:
        return str(resp).strip()


def _judge_pick_best(
    llm: ChatUpstage, llm_summary: str, rag_summary: str, context: str
) -> Dict[str, Any]:
    """
    LLM ìš”ì•½ vs RAG ìš”ì•½ ì¤‘ ë” ë‚˜ì€ ê²ƒì„ ì„ íƒí•©ë‹ˆë‹¤.
    ìš°ì„ ìˆœìœ„: ê·¼ê±°ì¼ì¹˜/ì‚¬ì‹¤ì„± > í•µì‹¬ ì»¤ë²„ë¦¬ì§€ > ê°„ê²°ì„±
    """
    llm_summary = (llm_summary or "").strip()
    rag_summary = (rag_summary or "").strip()
    context = (context or "").strip()

    if llm_summary and not rag_summary:
        return {"winner": "llm", "reason": "rag_summary_empty"}
    if rag_summary and not llm_summary:
        return {"winner": "rag", "reason": "llm_summary_empty"}
    if not llm_summary and not rag_summary:
        return {"winner": "llm", "reason": "both_empty"}

    prompt = (
        "ë„ˆëŠ” ìš”ì•½ ì‹¬ì‚¬ìœ„ì›ì´ë‹¤. CONTEXTë§Œì„ ê¸°ì¤€ìœ¼ë¡œ ë‘ ìš”ì•½ì„ í‰ê°€í•´ ë” ì¢‹ì€ ê²ƒì„ ê³ ë¥¸ë‹¤.\n"
        "í‰ê°€ ê¸°ì¤€(ì¤‘ìš”ë„ ìˆœ):\n"
        "1) ì‚¬ì‹¤ì„±/ê·¼ê±°ì¼ì¹˜: CONTEXTì— ì—†ëŠ” ë‚´ìš©ì„ ë§í•˜ë©´ í° ê°ì \n"
        "2) í•µì‹¬ ì»¤ë²„ë¦¬ì§€: ì¤‘ìš”í•œ ì •ë³´ê°€ ë¹ ì§€ë©´ ê°ì \n"
        "3) ê°„ê²°ì„±: ë¶ˆí•„ìš”í•œ ë§ì´ ë§ìœ¼ë©´ ê°ì \n\n"
        "ë°˜ë“œì‹œ JSONìœ¼ë¡œë§Œ ë‹µí•˜ë¼.\n"
        'í˜•ì‹: {"winner":"A"|"B","scoreA":0-10,"scoreB":0-10,"reason":"ì§§ê²Œ"}\n\n'
        f"CONTEXT:\n{context}\n\n"
        f"A (LLM_SUMMARY):\n{llm_summary}\n\n"
        f"B (RAG_SUMMARY):\n{rag_summary}\n"
    )

    resp = llm.invoke(prompt)

    raw = ""
    try:
        raw = (resp.content or "").strip()
    except Exception:
        raw = str(resp).strip()

    try:
        data = json.loads(raw)
        winner = data.get("winner")
        if winner == "A":
            return {
                "winner": "llm",
                "scoreA": data.get("scoreA"),
                "scoreB": data.get("scoreB"),
                "reason": data.get("reason", ""),
            }
        if winner == "B":
            return {
                "winner": "rag",
                "scoreA": data.get("scoreA"),
                "scoreB": data.get("scoreB"),
                "reason": data.get("reason", ""),
            }
    except Exception:
        pass

    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ: ê·¼ê±° ê¸°ë°˜ì„ ìš°ì„ (ì•ˆì „)
    return {"winner": "rag", "reason": "judge_parse_failed"}


# -----------------------------
# 4) Public: verify_summary_with_rag()
#    (nodes.pyê°€ ê¸°ëŒ€í•˜ëŠ” ë°˜í™˜ í˜•íƒœë¡œ ë§ì¶¤)
# -----------------------------
def _split_sentences_ko(text: str) -> List[str]:
    """
    ëŸ¬í”„ ë¬¸ì¥ ë¶„ë¦¬. (ë„ˆë¬´ ì™„ë²½í•  í•„ìš” ì—†ìŒ: ê²€ì¦/ê·¼ê±°ë¶€ì°©ìš©)
    """
    text = (text or "").strip()
    if not text:
        return []
    parts = re.split(r"(?<=[\.\?\!ã€‚ï¼ï¼Ÿ])\s+|\n+", text)
    return [p.strip() for p in parts if p.strip()]


def verify_summary_with_rag(
    llm: ChatUpstage,
    article_text: str,
    summary_draft: str,
    per_sentence_k: int = 3,
    top_k: int = 8,
    rerank_top: int = 4,
    relevance_threshold: float = 0.20,
    max_context_chars: int = 2800,
    **kwargs: Any,
) -> Dict[str, Any]:
    """
    ìš”ì•½ ê²€ì¦(RAG) + (NEW) LLMìš”ì•½ vs RAGìš”ì•½ A/B ì„ íƒ:
    - LLM ìš”ì•½(summary_draft) í›„ë³´ì™€, CONTEXT ê¸°ë°˜ RAG ìš”ì•½ í›„ë³´ë¥¼ ê°ê° ìƒì„±
    - ì‹¬íŒ LLMì´ ë” ì¢‹ì€ í›„ë³´ë¥¼ ì„ íƒ
    - ì„ íƒëœ ìš”ì•½ì„ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìª¼ê°œ ê° ë¬¸ì¥ë³„ ê·¼ê±°ë¥¼ ì°¾ì•„ [C#] ë¶€ì°©
    - ë°˜í™˜: verified_summary/context/citations/used_citations/unsupported_sentences (+ë””ë²„ê·¸ í‚¤)
    """
    vs = build_vectorstore(article_text)
    global_query = rewrite_query(llm, article_text)

    # ğŸ”§ ìˆ˜ì • ì‚¬í•­/ì£¼ì„ ë¸”ë¡ ì œê±° (ìµœì¢… ìš”ì•½ë§Œ ê²€ì¦)
    summary_draft = (summary_draft or "").split("â€» ìˆ˜ì • ì‚¬í•­:")[0].strip()

    # -----------------------------
    # (NEW) A/B: LLM ìš”ì•½ vs RAG ìš”ì•½ ìƒì„± & ì„ íƒ
    # -----------------------------
    llm_summary_candidate = summary_draft

    # ê¸°ì‚¬ ì „ì²´ ê¸°ë°˜ context êµ¬ì„± (ì „ì—­ RAG ìš”ì•½ ìƒì„±ìš©)
    _q, global_context, _global_citations = retrieve_context(
        llm=llm,
        article_text=article_text,
        top_k=top_k,
        rerank_top=rerank_top,
        relevance_threshold=relevance_threshold,
        max_context_chars=max_context_chars,
    )

    rag_summary_candidate = _make_rag_summary(llm, global_context)

    judge_ab = _judge_pick_best(
        llm=llm,
        llm_summary=llm_summary_candidate,
        rag_summary=rag_summary_candidate,
        context=global_context,
    )

    if judge_ab.get("winner") == "rag":
        summary_draft = rag_summary_candidate or llm_summary_candidate
        chosen_source = "rag"
    else:
        summary_draft = llm_summary_candidate or rag_summary_candidate
        chosen_source = "llm"

    # âœ… ë””ë²„ê·¸ ë¡œê·¸ (A/B ì„ íƒ í™•ì¸ìš©)
    print(
        f"[RAG-A/B] chosen={chosen_source} "
        f"scoreA={judge_ab.get('scoreA')} "
        f"scoreB={judge_ab.get('scoreB')} "
        f"reason={judge_ab.get('reason')}"
    )
    

    sentences = _split_sentences_ko(summary_draft)
    if not sentences:
        return {
            "query": global_query,
            "verified_summary": "",
            "context": "",
            "citations": [],
            "used_citations": [],
            "unsupported_sentences": [],
            # (NEW)
            "llm_summary": llm_summary_candidate,
            "rag_summary": rag_summary_candidate,
            "chosen_summary_source": chosen_source,
            "judge_ab": judge_ab,
        }

    cite_text_to_id: Dict[str, str] = {}
    citations: List[Dict[str, Any]] = []
    used_citations: List[str] = []
    unsupported_sentences: List[str] = []

    def _get_or_make_cid(text: str) -> str:
        t = text.strip()
        if t in cite_text_to_id:
            return cite_text_to_id[t]
        cid = f"C{len(citations) + 1}"
        cite_text_to_id[t] = cid
        citations.append({"id": cid, "text": t})
        return cid

    verified_lines: List[str] = []
    for sent in sentences:
        cands = retrieve_candidates(vs, query=sent, k=max(top_k, per_sentence_k))
        filtered = [c for c in cands if c["relevance"] >= relevance_threshold]

        if not filtered:
            unsupported_sentences.append(sent)
            verified_lines.append(sent)
            continue

        try:
            ranked = rerank_with_llm(
                llm, query=sent, candidates=filtered, take=max(per_sentence_k, 1)
            )
        except Exception:
            ranked = sorted(filtered, key=lambda x: x["relevance"], reverse=True)[
                : max(per_sentence_k, 1)
            ]

        cids: List[str] = []

        def _add_unique_from(
            rows: List[Dict[str, Any]], limit: int, relax_factor: float = 1.0
        ):
            nonlocal cids
            if not rows:
                return
            min_rel = relevance_threshold * relax_factor
            for r in rows:
                if len(cids) >= limit:
                    break
                if float(r.get("relevance", 0.0)) < min_rel:
                    continue
                t = (r.get("text") or "").strip()
                if not t:
                    continue
                cid = _get_or_make_cid(t)
                if cid not in cids:
                    cids.append(cid)

        _add_unique_from(ranked, per_sentence_k, relax_factor=1.0)

        if len(cids) < max(1, per_sentence_k):
            backup = sorted(filtered, key=lambda x: x["relevance"], reverse=True)
            _add_unique_from(backup, per_sentence_k, relax_factor=0.6)

        if not cids:
            unsupported_sentences.append(sent)
            verified_lines.append(sent)
            continue

        for cid in cids:
            if cid not in used_citations:
                used_citations.append(cid)

        verified_lines.append(sent + " " + " ".join([f"[{cid}]" for cid in cids]))

    context_blocks: List[str] = []
    total = 0
    for c in citations:
        block = f"[{c['id']}] {c['text']}"
        if total + len(block) > max_context_chars:
            break
        context_blocks.append(block)
        total += len(block)

    context = "\n\n".join(context_blocks)
    verified_summary = "\n".join(verified_lines).strip()

    return {
        "query": global_query,
        "verified_summary": verified_summary,
        "context": context,
        "citations": citations,
        "used_citations": used_citations,
        "unsupported_sentences": unsupported_sentences,
        # (NEW) ê´€ì°°/ë””ë²„ê·¸ìš© (í˜¸ì¶œì ê¹¨ì§€ì§€ ì•ŠìŒ)
        "llm_summary": llm_summary_candidate,
        "rag_summary": rag_summary_candidate,
        "chosen_summary_source": chosen_source,
        "judge_ab": judge_ab,
    }
