import os
import json
import re
from typing import Any, Dict, List, Tuple, Optional

from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain_core.retrievers import BaseRetriever

# âœ… LangChain ë²„ì „ ì°¨ì´(íŒ¨í‚¤ì§€/ê²½ë¡œ) í˜¸í™˜ ì²˜ë¦¬
try:
    from langchain_text_splitters import RecursiveCharacterTextSplitter
except Exception:
    from langchain.text_splitter import RecursiveCharacterTextSplitter

from agent.prompts import QUERY_REWRITE_PROMPT, RERANK_PROMPT


# -----------------------------
# 1) Vectorstore / Query Rewrite
# -----------------------------
def build_vectorstore(text: str) -> FAISS:
    """ê¸°ì‚¬ ì›ë¬¸ì„ ì²­í¬ë¡œ ìª¼ê°œ ì„ë² ë”©í•œ ë’¤, FAISS ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=120,
        separators=["\n\n", "\n", ". ", "? ", "! ", " "],
    )
    chunks = splitter.split_text(text or "")

    embeddings = UpstageEmbeddings(
        model="solar-embedding-1-large",
        api_key=os.environ["UPSTAGE_API_KEY"],
    )
    return FAISS.from_texts(chunks, embeddings)


def _clean_llm_query_output(s: str, max_len: int = 160) -> str:
    """rewrite_query ì¶œë ¥ì—ì„œ ë©”íƒ€ í…ìŠ¤íŠ¸/ë”°ì˜´í‘œ/ë§ˆí¬ë‹¤ìš´ ì œê±°"""
    s = (s or "").strip()

    s = re.sub(r"^\*+\s*ì¿¼ë¦¬\s*\*+\s*:\s*", "", s, flags=re.IGNORECASE)
    s = re.sub(r"^\s*query\s*:\s*", "", s, flags=re.IGNORECASE)

    cut_markers = ["\n", "citations:", "**ìµœì¢…", "ìµœì¢… ì¶œë ¥", "ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­", "(â€»"]
    for m in cut_markers:
        if m in s:
            s = s.split(m, 1)[0].strip()

    if ' "' in s:
        s = s.split(' "', 1)[0].strip()
    if '"' in s and s.count('"') >= 1:
        s = s.split('"', 1)[0].strip()

    s = re.sub(r"\*\*ìµœì¢…\s*ë‹µë³€\*\*|ìµœì¢…\s*ë‹µë³€|ì‹¤ì œ\s*ë‹µë³€", "", s).strip()

    s = s.strip().strip('"').strip("'")
    s = re.sub(r"\s+", " ", s).strip()

    if len(s) > max_len:
        s = s[:max_len].rstrip(" ,.;")

    return s


def rewrite_query(llm: ChatUpstage, article_text: str) -> str:
    """ê¸°ì‚¬ ì¼ë¶€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²€ìƒ‰ ìµœì í™” ì¿¼ë¦¬ë¥¼ 1ë¬¸ì¥ìœ¼ë¡œ ì¬ì‘ì„±í•©ë‹ˆë‹¤."""
    snippet = (article_text or "")[:1800]
    prompt = QUERY_REWRITE_PROMPT.strip() + "\n\n" + snippet

    resp = llm.invoke(prompt)

    try:
        content = (resp.content or "").strip()
    except Exception:
        content = str(resp).strip()

    content = content.strip().strip('"').strip("'").strip()

    if not content:
        content = "ê¸°ì‚¬ í•µì‹¬(ìˆ˜ì¹˜/ë¹„êµ/ê¸°ëŠ¥/ì¡°ê±´/ë°œì–¸)ì„ ìš”ì•½í•˜ê¸° ìœ„í•œ ê·¼ê±° ë¬¸ì¥ ê²€ìƒ‰ ì¿¼ë¦¬"

    return _clean_llm_query_output(content)


def _to_relevance(score: float) -> float:
    """FAISS scoreë¥¼ 0~1 relevanceë¡œ ë³€í™˜."""
    try:
        return 1.0 / (1.0 + float(score))
    except Exception:
        return 0.0


# -----------------------------
# 2) Retriever (optional rerank)
# -----------------------------
def retrieve_candidates(vs: FAISS, query: str, k: int = 8) -> List[Dict[str, Any]]:
    pairs = vs.similarity_search_with_score(query, k=k)
    cands: List[Dict[str, Any]] = []
    for idx, (doc, score) in enumerate(pairs, start=1):
        cid = f"C{idx}"
        cands.append(
            {
                "id": cid,
                "text": doc.page_content,
                "score": float(score),
                "relevance": _to_relevance(score),
            }
        )
    return cands


def rerank_with_llm(
    llm: ChatUpstage,
    query: str,
    candidates: List[Dict[str, Any]],
    take: int = 4,
) -> List[Dict[str, Any]]:
    """
    LLMìœ¼ë¡œ í›„ë³´ë¥¼ ì¬ì •ë ¬í•©ë‹ˆë‹¤.
    RERANK_PROMPTëŠ” ["C3","C1",...] ê°™ì€ id ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ë„ë¡ ì„¤ê³„ë˜ì–´ì•¼ í•¨.
    ì‹¤íŒ¨ ì‹œ relevance ìˆœìœ¼ë¡œ fallback.
    """
    payload = {
        "query": query,
        "candidates": [
            {"id": c["id"], "text": (c["text"][:400] if c.get("text") else "")}
            for c in candidates
        ],
    }

    resp = llm.invoke(RERANK_PROMPT + "\n\n" + json.dumps(payload, ensure_ascii=False))

    picked_ids: List[str] = []
    try:
        picked = json.loads(resp.content)
        if isinstance(picked, list):
            picked_ids = [x for x in picked if isinstance(x, str)]
    except Exception:
        picked_ids = []

    if not picked_ids:
        picked_ids = [
            c["id"]
            for c in sorted(candidates, key=lambda x: x["relevance"], reverse=True)[:take]
        ]

    id2 = {c["id"]: c for c in candidates}
    ranked = [id2[i] for i in picked_ids if i in id2]
    return ranked[:take]


def pack_context(
    ranked: List[Dict[str, Any]],
    max_chars: int = 2800,
) -> Tuple[str, List[Dict[str, Any]]]:
    """
    ì„ ì •ëœ ê·¼ê±°ë¥¼ [C#] ë§ˆì»¤ì™€ í•¨ê»˜ í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ì¢‹ì€ ë¬¸ìì—´ë¡œ í•©ì¹©ë‹ˆë‹¤.
    ë°˜í™˜: (context_str, citations=[{"id": "C1", "text": "..."}...])
    """
    seen = set()
    packed: List[Dict[str, Any]] = []
    total = 0

    for c in ranked:
        t = (c.get("text") or "").strip()
        if not t or t in seen:
            continue
        seen.add(t)

        piece = f"[{c['id']}] {t}"
        if total + len(piece) > max_chars:
            break

        packed.append({"id": c["id"], "text": t})
        total += len(piece)

    context = "\n\n".join([f"[{p['id']}] {p['text']}" for p in packed])
    return context, packed


class KafkaMiniRetriever(BaseRetriever):
    """í˜„ì¬ í”„ë¡œì íŠ¸ RAG ê²€ìƒ‰ ë¡œì§ì„ LangChain Retriever í˜•íƒœë¡œ ë˜í•‘."""
    model_config = {"arbitrary_types_allowed": True}

    vectorstore: FAISS
    llm: ChatUpstage
    top_k: int = 8
    relevance_threshold: float = 0.20
    rerank_top: int = 4

    def _get_relevant_documents(self, query: str) -> List[Document]:
        candidates = retrieve_candidates(self.vectorstore, query=query, k=self.top_k)
        filtered = [c for c in candidates if c["relevance"] >= self.relevance_threshold]
        if not filtered:
            return []

        ranked = rerank_with_llm(self.llm, query=query, candidates=filtered, take=self.rerank_top)

        docs: List[Document] = []
        for c in ranked:
            docs.append(
                Document(
                    page_content=c["text"],
                    metadata={
                        "cid": c["id"],
                        "score": c["score"],
                        "relevance": c["relevance"],
                    },
                )
            )
        return docs


def _strip_citation_markers(text: str) -> str:
    """[C1] ê°™ì€ ë§ˆì»¤ ì œê±° (eval/ë¹„êµìš©)."""
    t = (text or "")
    t = re.sub(r"\s*\[C\d+\]\s*", " ", t)
    t = re.sub(r"\s+", " ", t).strip()
    return t


def _build_rag_candidate(
    llm: ChatUpstage,
    article_text: str,
    draft_summary: str,
    top_k: int,
    rerank_top: int,
    relevance_threshold: float,
    max_context_chars: int,
) -> Dict[str, Any]:
    """
    [RAG í›„ë³´ ìƒì„±] ê·¼ê±°(context) ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½ì„ 'ìƒˆë¡œ ì‘ì„±'í•˜ê³  [C#] ë§ˆì»¤ í¬í•¨.
    draft_summaryëŠ” ì°¸ê³ ë§Œ(coverage ë°©í–¥)í•˜ê³ , ì‚¬ì‹¤ì€ contextë¡œ ì œí•œ.
    """
    vs = build_vectorstore(article_text)
    global_query = rewrite_query(llm, article_text)

    candidates = retrieve_candidates(vs, query=global_query, k=top_k)
    filtered = [c for c in candidates if c["relevance"] >= relevance_threshold]
    ranked = rerank_with_llm(llm, query=global_query, candidates=filtered, take=rerank_top) if filtered else []

    context_str, citations = pack_context(ranked, max_chars=max_context_chars)

    if not context_str:
        return {
            "query": global_query,
            "context": "",
            "citations": [],
            "rag_candidate_summary": "",
            "rag_candidate_plain": "",
        }

    rag_gen_prompt = f"""
ë‹¹ì‹ ì€ ë‰´ìŠ¤ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ [ê·¼ê±° ë¬¸ì¥ë“¤]ì„ ì‚¬ìš©í•˜ì—¬ ê¸°ì‚¬ë¥¼ ìš”ì•½í•˜ì„¸ìš”.

[í•„ìˆ˜ ì§€ì¹¨]
1. ë°˜ë“œì‹œ ì œê³µëœ [ê·¼ê±° ë¬¸ì¥ë“¤]ì˜ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
2. ë¬¸ì¥ ì¤‘ê°„ì´ë‚˜ ëì— í•´ë‹¹ ì •ë³´ì˜ ê·¼ê±° ID(ì˜ˆ: [C1])ë¥¼ **ë°˜ë“œì‹œ í¬í•¨**í•˜ì„¸ìš”.
3. ì •ë³´ë¥¼ ì„ì˜ë¡œ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
4. ìš”ì•½ì€ 3ë¬¸ì¥ ì •ë„ë¡œ í•µì‹¬ë§Œ ì „ë‹¬í•˜ì„¸ìš”.

[ì„ íƒ ì§€ì¹¨]
- ì•„ë˜ ì´ˆì•ˆ(draft)ì€ ë…¼ì /ë²”ìœ„ ì°¸ê³ ìš©ì´ë©°, ì‚¬ì‹¤ì€ ê·¼ê±°ì—ì„œë§Œ ë½‘ìœ¼ì„¸ìš”.

[ì´ˆì•ˆ(draft)]
{draft_summary}

[ê·¼ê±° ë¬¸ì¥ë“¤]
{context_str}

ìµœì¢… ìš”ì•½:
""".strip()

    try:
        resp = llm.invoke(rag_gen_prompt)
        rag_summary = (resp.content or "").strip()
    except Exception:
        rag_summary = ""

    return {
        "query": global_query,
        "context": context_str,
        "citations": citations,
        "rag_candidate_summary": rag_summary,
        "rag_candidate_plain": _strip_citation_markers(rag_summary),
    }


def select_best_summary_with_fallback(
    llm: ChatUpstage,
    article_text: str,
    draft_summary: str,
    max_retry: int = 2,
    max_context_chars: int = 2800,
) -> Dict[str, Any]:
    """
    - RAG í›„ë³´ë¥¼ ì—¬ëŸ¬ íŒŒë¼ë¯¸í„°ë¡œ ìƒì„±í•˜ë©° best candidateë¥¼ ê³ ë¦„
    - eval_pairwiseë¡œ draft(A) vs rag_plain(B) í‰ê°€í•˜ì—¬ winner ì‚°ì¶œ
    """
    attempts = [
        dict(top_k=8,  rerank_top=4, relevance_threshold=0.20),
        dict(top_k=12, rerank_top=6, relevance_threshold=0.12),
        dict(top_k=16, rerank_top=8, relevance_threshold=0.08),
    ]
    max_retry = max(0, min(int(max_retry), len(attempts) - 1))

    try:
        from agent.eval_pairwise import eval_rag_vs_llm
    except Exception:
        eval_rag_vs_llm = None  # type: ignore

    best: Dict[str, Any] = {
        "winner": "UNKNOWN",
        "winner_reason": "",
        "rag_attempt_used": 0,
        "pairwise_report": None,
        "rag_pack": None,
    }
    best_b = -10

    for i in range(0, max_retry + 1):
        cfg = attempts[i]
        rag_pack = _build_rag_candidate(
            llm=llm,
            article_text=article_text,
            draft_summary=draft_summary,
            top_k=int(cfg["top_k"]),
            rerank_top=int(cfg["rerank_top"]),
            relevance_threshold=float(cfg["relevance_threshold"]),
            max_context_chars=int(max_context_chars),
        )

        rag_plain = rag_pack.get("rag_candidate_plain", "")

        winner = "UNKNOWN"
        reason = ""
        report = None
        b_score = -10

        if eval_rag_vs_llm and draft_summary and rag_plain:
            report = eval_rag_vs_llm(
                llm=llm,
                article_text=article_text,
                draft_summary=draft_summary,
                rag_summary=rag_plain,
            )
            try:
                w = (((report or {}).get("overall") or {}).get("winner") or "").upper()
                if w == "A":
                    winner = "LLM"
                elif w == "B":
                    winner = "RAG"
                elif w == "TIE":
                    winner = "TIE"
                else:
                    winner = "UNKNOWN"
                reason = (((report or {}).get("overall") or {}).get("reason") or "")
            except Exception:
                winner = "UNKNOWN"

            try:
                b_score = int(((report.get("overall") or {}).get("b")) or 0)
            except Exception:
                b_score = 0

        # best ì—…ë°ì´íŠ¸
        if b_score > best_b:
            best_b = b_score
            best = {
                "winner": winner,
                "winner_reason": reason,
                "rag_attempt_used": i,
                "pairwise_report": report,
                "rag_pack": rag_pack,
            }

        # RAGê°€ ì´ê¸´ ìˆœê°„ ë¹ ë¥¸ ì¢…ë£Œ (ì„±ê³µ ì‹œë„ ìš°ì„ )
        if winner == "RAG":
            break

    return best


def verify_summary_with_rag(
    llm: ChatUpstage,
    article_text: str,
    summary_draft: str,
    max_retry: int = 2,
    max_context_chars: int = 2800,
    **kwargs: Any,
) -> Dict[str, Any]:
    """
    âœ… ìµœì¢… ì •ì±…(ì„œë¹„ìŠ¤ ëª©í‘œ ë°˜ì˜):
    - í›„ë³´ A: LLM-only draft_summary
    - í›„ë³´ B: RAG í›„ë³´(ê·¼ê±° ê¸°ë°˜ ìƒˆ ìš”ì•½) => rag_candidate_summary(+ [C#]) / rag_candidate_plain
    - pairwise winnerì— ë”°ë¼ ìµœì¢… ìš”ì•½(verified_summary)ì„ ê²°ì •
      * RAG or TIE => RAG ì±„íƒ(ê·¼ê±°ì™€ í•¨ê»˜)
      * LLM => LLM ì±„íƒ(ê·¼ê±°/ì¸ìš©ì€ ìµœì¢… ì¶œë ¥ìš©ìœ¼ë¡œëŠ” ë¹„ì›€)
      * UNKNOWN => ì•ˆì „í•˜ê²Œ LLM ì±„íƒ
    - ë‹¨, íŠœë‹/ê°œì„  ë£¨í”„ìš©ìœ¼ë¡œ rag_context/rag_citationsëŠ” í•­ìƒ í•¨ê»˜ ë°˜í™˜
    """
    picked = select_best_summary_with_fallback(
        llm=llm,
        article_text=article_text,
        draft_summary=summary_draft,
        max_retry=max_retry,
        max_context_chars=max_context_chars,
    )

    rag_pack = picked.get("rag_pack") or {}
    winner = (picked.get("winner") or "UNKNOWN").upper()

    rag_candidate_summary = rag_pack.get("rag_candidate_summary", "") or ""
    rag_candidate_plain = rag_pack.get("rag_candidate_plain", "") or ""
    rag_query = rag_pack.get("query", "") or ""
    rag_context = rag_pack.get("context", "") or ""
    rag_citations = rag_pack.get("citations", []) or []

    # âœ… ìµœì¢… ì„ íƒ
    if winner in ["RAG", "TIE"]:
        final_source = "RAG"
        final_summary = rag_candidate_summary or summary_draft
        final_citations = rag_citations
        final_context = rag_context
        used_citations = [c.get("id") for c in rag_citations if isinstance(c, dict)]
    elif winner == "LLM":
        final_source = "LLM"
        final_summary = summary_draft or ""
        # ğŸ”¥ ìµœì¢… ì¶œë ¥ì€ LLMì´ë©´ citations/context ë¹„ì›€ (ë…¸ì¶œ ë¦¬ìŠ¤í¬ ì°¨ë‹¨)
        final_citations = []
        final_context = ""
        used_citations = []
    else:
        # UNKNOWN => ì•ˆì „í•˜ê²Œ LLM ì±„íƒ
        final_source = "LLM"
        final_summary = summary_draft or ""
        final_citations = []
        final_context = ""
        used_citations = []

    return {
        # í›„ë³´ë“¤
        "llm_candidate_summary": summary_draft or "",
        "rag_candidate_summary": rag_candidate_summary,
        "rag_candidate_plain": rag_candidate_plain,

        # RAG ì¬ë£Œ(íŠœë‹/ë””ë²„ê·¸/ê°œì„ ë£¨í”„ìš©)
        "rag_query": rag_query,
        "rag_context": rag_context,
        "rag_citations": rag_citations,

        # ìµœì¢… ì¶œë ¥(ì„œë¹„ìŠ¤ìš©)
        "query": rag_query,               # ë¡œê·¸/ë””ë²„ê·¸ ëª©ì (ì›í•˜ë©´ final_sourceê°€ LLMì¼ ë•Œ ìˆ¨ê²¨ë„ ë¨)
        "context": final_context,
        "citations": final_citations,
        "used_citations": used_citations,
        "verified_summary": final_summary,

        # ì„ íƒ ì •ë³´
        "winner": winner,
        "final_source": final_source,
        "winner_reason": picked.get("winner_reason") or "",
        "rag_attempt_used": picked.get("rag_attempt_used", 0),
        "pairwise_report": picked.get("pairwise_report"),
        "unsupported_sentences": [],  # í˜„ì¬ëŠ” ìƒˆë¡œ ìƒì„±ì´ë¼ ë¬¸ì¥ ë‹¨ìœ„ unsupported ì˜ë¯¸ ë‚®ìŒ
    }
